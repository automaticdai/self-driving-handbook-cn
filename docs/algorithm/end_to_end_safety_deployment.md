# 安全与部署体系：可解释、验证、上线与回滚

本页聚焦端到端系统从实验室到量产的工程闭环，涵盖可解释性、安全架构、验证体系与上线流程。

---

## 1. 可解释性与可观测性

### 1.1 为什么端到端模型难以解释

与模块化系统相比，端到端模型的决策过程是"黑盒"：

```
模块化系统：
  感知输出（目标列表）→ 预测（轨迹分布）→ 规划（显式代价最优）→ 控制
  每一步都有可解读的中间表示

端到端系统：
  传感器输入 → 神经网络（参数几百亿）→ 驾驶行为
  中间表示难以直接对应物理含义
```

### 1.2 可解释性技术

| 技术 | 原理 | 局限 |
| --- | --- | --- |
| Attention 可视化 | 查看 Transformer 注意力权重 | 注意力≠因果，可能误导 |
| GradCAM | 用梯度定位对决策影响最大的图像区域 | 局部解释，不含时序 |
| SHAP | 博弈论 Shapley 值，衡量特征贡献 | 计算成本高 |
| 显著图（Saliency Map） | 输入扰动后输出变化量 | 解释局部，不稳定 |
| 概念激活向量（TCAV） | 测试模型是否对人类概念有响应 | 需要预定义概念 |

### 1.3 工程可观测性最低要求

即使无法完全解释模型内部，至少应输出：

```yaml
model_output:
  trajectory: [...]          # 主输出
  confidence: 0.92           # 轨迹置信度
  risk_score: 0.15           # 场景风险评分（0-1）
  key_objects:               # 对决策影响最大的目标
    - id: 3
      type: "pedestrian"
      influence: 0.68        # 影响权重
  uncertainty_estimate: 0.08 # 不确定性估计
  ood_score: 0.03            # 分布外（OOD）程度评分
```

---

## 2. 不确定性估计

### 2.1 不确定性类型

| 类型 | 来源 | 处理方式 |
| --- | --- | --- |
| 认识不确定性（Epistemic） | 模型知识不足（训练数据不覆盖的场景） | 增加训练数据，贝叶斯方法 |
| 偶然不确定性（Aleatoric） | 数据本身的噪声（传感器噪声、标注噪声） | 预测概率分布而非点估计 |

### 2.2 实用估计方法

**MC Dropout（训练时和推理时都启用 Dropout）：**

$$\text{Var}(\hat{y}) \approx \frac{1}{T}\sum_{t=1}^T \hat{y}_t^2 - \left(\frac{1}{T}\sum_{t=1}^T \hat{y}_t\right)^2$$

进行 T 次前向推理，方差大的样本为高不确定性样本。

**Deep Ensemble：**

训练 5–10 个不同初始化的模型，不一致程度代表不确定性：

$$\sigma^2 = \frac{1}{M}\sum_{m=1}^M (\hat{y}_m - \bar{y})^2$$

---

## 3. 安全层架构

### 3.1 三层安全架构

```
┌─────────────────────────────────────────────────────┐
│                端到端主模型层                        │
│  输入：多传感器数据                                  │
│  输出：候选轨迹 + 置信度 + 风险评分                  │
└───────────────────────┬─────────────────────────────┘
                        │
┌───────────────────────↓─────────────────────────────┐
│                安全约束层（Safety Layer）             │
│  ├─ 碰撞检测：预测轨迹 + 感知障碍物碰撞校验          │
│  ├─ 动力学校验：加速度/曲率超限过滤                  │
│  ├─ 法规合规：限速、停止线、禁止越线                 │
│  └─ OOD 检测：评分过高时触发降级                    │
└───────────────────────┬─────────────────────────────┘
                        │
┌───────────────────────↓─────────────────────────────┐
│                控制执行层                            │
│  执行安全层过滤后的轨迹指令                          │
└─────────────────────────────────────────────────────┘
```

### 3.2 Runtime Monitor（运行时监控器）

形式化规则监控器，实时检测语义违规：

```python
class RuntimeMonitor:
    def check(self, state, trajectory):
        violations = []

        # TTC 检查
        for obj in state.objects:
            ttc = compute_ttc(trajectory, obj)
            if ttc < 1.0:
                violations.append(f"TTC_VIOLATION: {obj.id}")

        # 限速检查
        speed_limit = state.map.speed_limit
        if max(trajectory.v) > speed_limit * 1.1:
            violations.append("SPEED_LIMIT_VIOLATION")

        return violations
```

---

## 4. OOD（分布外）检测

### 4.1 检测方法

| 方法 | 原理 | 适用 |
| --- | --- | --- |
| 能量分数（Energy Score） | 模型输出 logits 的能量值 | 分类任务 |
| Mahalanobis 距离 | 特征到训练分布中心的马氏距离 | 通用 |
| 密度估计（NF/VAE） | 用生成模型估计输入概率密度 | 高精度，计算代价高 |
| KNN OOD | 测试样本到最近训练样本的距离 | 简单有效 |

### 4.2 OOD 触发的响应

```
OOD 分数低（<0.1）：正常运行
    │
OOD 分数中（0.1-0.3）：记录日志，提高安全余量
    │
OOD 分数高（>0.3）：切换至保守模式（规则模块接管）
    │
OOD 分数极高（>0.7）：触发 TOR → MRC
```

---

## 5. 验证体系

### 5.1 四级验证框架

```
Level 1：离线回放（Offline Replay）
  - 将历史数据喂给模型，比较输出与真实驾驶的差异
  - 规模：数百万帧，全自动
  - 局限：无交互，无因果

Level 2：闭环仿真（Closed-loop Sim）
  - 在仿真环境中执行模型决策，观察后续状态演化
  - 规模：数万场景，全自动
  - 挑战：仿真保真度，Reality Gap

Level 3：台架/HIL 测试
  - 真实 ECU + 仿真环境，验证时延、接口、硬件行为
  - 重点：时序约束、异常恢复

Level 4：实车测试
  - 真实道路环境，有安全员
  - 重点：系统稳定性、用户体验、长尾发现
```

### 5.2 影子模式（Shadow Mode）

影子模式是端到端系统上线的关键前置步骤：

```
车辆正常运行（由旧系统控制）
          │
          ↓ 同步
新的端到端模型并行运行（不控车）
          │
          ↓ 持续比较
  新旧系统决策差异统计：
  ├─ 横向偏差分布
  ├─ 速度规划差异
  ├─ 高风险分歧点
  └─ OOD 触发率
```

通过影子模式：

- 不承担实车风险地评估新模型
- 收集大量真实场景数据
- 建立"新旧系统一致性"基线

---

## 6. 上线流程

### 6.1 分阶段发布

```
阶段 0：影子模式（100% 车辆，不控车，2–4 周）
  门禁：分歧率 < 阈值，OOD 率 < 阈值，无安全事件

阶段 1：小流量灰度（1–5% 车辆，有安全员）
  门禁：接管率 ≤ 基线 × 110%，碰撞率 = 0

阶段 2：区域扩容（特定城市，10–30% 车辆）
  门禁：同阶段 1 + 用户体验指标

阶段 3：全量发布（所有车辆）
  门禁：7 天观察期无重大异常
```

### 6.2 每个阶段的门禁指标

| 指标 | 门禁标准 |
| --- | --- |
| 接管率 | 不超过当前版本 × 110% |
| 安全事件率 | = 0（严重）或 ≤ 基线（轻微） |
| 违规触发率 | ≤ 基线 × 105% |
| 平顺性（RMS jerk） | ≤ 基线 × 110% |
| OOD 触发率 | ≤ 5% |

---

## 7. 回滚策略

### 7.1 回滚触发条件

| 触发条件 | 响应时间 | 回滚范围 |
| --- | --- | --- |
| 严重安全事件（碰撞/接近碰撞） | 即时 | 全量车辆 |
| 接管率超过红线 | 1 小时内 | 该批次灰度车辆 |
| 关键指标持续恶化 | 24 小时内 | 按区域回滚 |
| 用户投诉显著上升 | 24–72 小时 | 视严重程度 |

### 7.2 技术回滚实现

- A/B 分区保留旧版本，随时可切换
- 回滚命令通过 OTA 通道下发，执行时间 < 5 分钟
- 回滚后自动通知 OPS 和研发团队

---

## 8. 模型漂移监控

### 8.1 数据分布漂移检测

```python
# 使用 KL 散度监控特征分布变化
def detect_distribution_drift(ref_features, current_features):
    kl_divergence = compute_kl(ref_features, current_features)
    if kl_divergence > threshold:
        alert("DISTRIBUTION_DRIFT", kl_divergence)
```

### 8.2 长期运营监控

| 监控项 | 频率 | 告警条件 |
| --- | --- | --- |
| 接管率周趋势 | 每日 | 连续 3 天上升 > 5% |
| 感知指标（在线评估） | 每日 | mAP 下降 > 2% |
| OOD 触发率 | 每日 | 上升 > 10% |
| 用户体验评分（NPS） | 每周 | 下降 > 5 分 |

---

## 9. 合规要求参考

| 标准 | 内容 | 相关性 |
| --- | --- | --- |
| ISO 26262 | 功能安全，ASIL 等级 | 安全层设计 |
| ISO 21448 (SOTIF) | 预期功能安全（针对 AI 感知）| ODD 边界，OOD 处理 |
| UN R157 | 自动车道保持系统认证 | 横向控制安全 |
| NHTSA AV 4.0 | 美国自动驾驶安全框架 | 上市合规参考 |
