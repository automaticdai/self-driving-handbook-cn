# 百度 Apollo

百度 Apollo 是中国最具影响力的自动驾驶开放平台，于 2017 年 4 月正式发布，以"阿波罗登月计划"为名，寓意用开放合作推动中国自动驾驶技术腾飞。Apollo 采用"开放能力、共建生态"的策略，向行业开放感知、规划、控制等核心模块，同时积累商业化运营数据。截至 2024 年，Apollo 已成为全球最大的自动驾驶开放生态，萝卜快跑累计服务订单突破 **600 万次**，是全球落地最深的 L4 级 Robotaxi 商业服务。


## 平台演进历程

| 版本 | 发布时间 | 核心里程碑 | 关键技术突破 |
| --- | --- | --- | --- |
| Apollo 1.0 | 2017.07 | 封闭场地循环路线自动驾驶 | RTK GPS 定位，开放 LQR 控制模块 |
| Apollo 2.0 | 2018.01 | 简单城市道路场景 | 激光雷达感知，高精地图集成，障碍物检测 |
| Apollo 3.0 | 2018.07 | 低速园区全自动驾驶，Valet Parking | 代客泊车场景，停车场地图，超声波融合 |
| Apollo 3.5 | 2019.01 | 复杂城市道路，裸奔场景处理 | **Cyber RT** 替代 ROS，BEV 感知雏形 |
| Apollo 5.0 | 2019.07 | 城市开放道路 L4 级，ANP 高速辅助 | 深度学习端到端感知，高速 NOA 功能 |
| Apollo 5.5 | 2020.01 | 激光雷达-视觉深度融合 | 多任务感知网络，障碍物预测升级 |
| Apollo 6.0 | 2020.09 | 云端训练闭环，数据驱动迭代 | 仿真平台 Apollo Sim 发布，自动标注 |
| Apollo 7.0 | 2021.11 | 全场景感知增强，NLP 指令驾驶 | 语音交互驾驶，Transformer 感知引入 |
| Apollo RT6 | 2022.07 | 第六代 Robotaxi，成本 25 万元 | 双 Orin X，全栈自研传感器，全无人运营 |

Apollo 版本演进体现了三个阶段的战略转变：**技术验证期**（1.0–3.0）从封闭场地走向简单城市道路；**能力深化期**（3.5–6.0）以 Cyber RT 为核心重构架构，深度学习全面替代传统算法；**商业落地期**（7.0–RT6）以降本为核心目标，推动 Robotaxi 规模商业化。


## Cyber RT 架构深度分析

Apollo 3.5 版本以 Cyber RT 替代 ROS 1，彻底重构了车端通信与调度框架。Cyber RT 是专为自动驾驶设计的高性能中间件，其设计目标是：**确定性低延迟 + 高吞吐量 + 模块热插拔**。

### 协程调度模型

Cyber RT 放弃了传统的线程池模型，引入**协程（Coroutine / Fiber）**作为基本执行单元：

```
传统线程模型：
  线程1 ──► [等待消息] ──► [阻塞] ──► [上下文切换（~5 μs）] ──► ...
  线程2 ──► [等待消息] ──► [阻塞] ──► [上下文切换] ──► ...

Cyber RT 协程模型：
  工作线程1 ──► [协程A] ──► [yield] ──► [协程B] ──► [yield] ──► [协程C] ──► ...
  工作线程2 ──► [协程D] ──► [yield] ──► [协程E] ──► ...
              ↑ 用户态切换（< 0.1 μs），无系统调用开销
```

Cyber RT 的调度器（Scheduler）根据任务优先级、消息到达顺序动态调度协程，支持以下两种触发模式：

- **数据驱动（Data-driven）**：消息到达后立即触发对应组件的 `Proc()` 回调，适合感知、预测等数据流组件
- **时间驱动（Timer-driven）**：按固定频率触发，适合控制模块（100 Hz）等周期性任务

### DAG 任务依赖图

Cyber RT 以 **DAG（有向无环图，Directed Acyclic Graph）** 描述模块间的依赖关系和数据流向：

```
[Camera Component]────────────────────────────────────────────►[感知融合]
                                                                    │
[LiDAR Component]─────────────────────────►[3D检测 Component]──────┤
                                                                    │
[Radar Component]─────────────[目标跟踪 Component]─────────────────┤
                                                                    ▼
[定位 Component]──────────────────────────────────────────────►[规划 Component]──►[控制 Component]
```

DAG 配置通过 `.dag` 文件声明，Cyber RT 在启动时解析拓扑关系，自动分配协程优先级和 CPU 亲和性。

### 共享内存通信

对于大数据量的传感器数据（4K 摄像头图像约 24 MB/帧，128线 LiDAR 点云约 10 MB/帧），Cyber RT 使用**共享内存（Shared Memory）** 实现零拷贝传输：

| 传输方式 | 适用场景 | 延迟 | 带宽限制 |
| --- | --- | --- | --- |
| 进程内直接引用 | 同进程模块通信 | < 1 μs | 无 |
| 共享内存（POSIX shm） | 跨进程大数据（图像/点云） | 1–5 μs | 受内存带宽限制（~50 GB/s） |
| TCP/UDP Socket | 跨机器通信（车-云） | > 100 μs | 受网络带宽限制 |

消息发布时，生产者仅向通道写入指向共享内存块的**描述符（Handle）**，消费者通过描述符直接访问数据，避免了大块数据的内存拷贝，使 Camera 图像传输延迟从 ROS 的约 5 ms 降低至 1 ms 以内。

### Cyber RT vs ROS 2 关键指标对比

| 指标 | ROS 2 (Humble) | Cyber RT | 说明 |
| --- | --- | --- | --- |
| 节点间消息延迟（1 MB） | 5–15 ms | 1–3 ms | 共享内存 vs DDS |
| 最大消息吞吐量 | ~500 MB/s | ~2 GB/s | 受 DDS 中间层限制 |
| 任务切换开销 | ~5 μs（线程切换） | ~0.1 μs（协程切换） | 用户态 vs 内核态 |
| 实时性保证 | 依赖 DDS QoS | 原生优先级调度 | 硬实时需额外 RTOS |
| 模块热插拔 | 支持（节点级） | 支持（组件级） | Cyber RT 粒度更细 |


## Apollo 感知系统

Apollo 感知模块整合多传感器数据，通过多个子模块协作，输出统一的目标列表（Object List）和占用栅格（Occupancy Grid）。

### LiDAR 3D 目标检测流程

```
原始点云（128线 LiDAR, ~100万点/帧）
        │
        ▼
  地面点分割（RANSAC 平面拟合）
        │
        ▼
  体素化降采样（Voxel Grid, 0.1 m 分辨率）
        │
        ├──► PointPillars 网络推理（柱状体素特征提取）
        │           │
        │           ▼
        │    2D 伪图像（512×512）→ 2D CNN骨干网
        │           │
        └──► CenterPoint 网络（中心点检测）
                    │
                    ▼
          3D 边界框（BBox）输出：类别/位置/尺寸/朝向/速度
                    │
                    ▼
          多帧 LiDAR 融合（时间累积，改善稀疏性）
```

**PointPillars 的核心创新：** 将点云划分为垂直方向的柱（Pillar），在每根柱内用 PointNet 提取特征，生成伪图像后用标准 2D CNN 检测，推理速度较 VoxelNet 提升约 5 倍，RT6 上单帧处理时间约 **20 ms**。

### BEV 视觉感知

Apollo RT6 引入多摄像头鸟瞰视角（BEV）感知，解决了传统透视视角感知的尺度歧义问题：

```
12个摄像头（前/后/左/右/斜角）
        │
        ▼
  各路图像独立 CNN 特征提取（ResNet-50 骨干）
        │
        ▼
  视角转换（View Transformer）：
  透视特征 → BEV 特征
  方法：LSS（Lift-Splat-Shoot）或 BEVFormer（Deformable Attention）
        │
        ▼
  BEV 特征图（200×200，分辨率 0.5 m/格）
        │
        ├──► 3D 目标检测头（车辆/行人/骑行者）
        ├──► 车道线检测头
        └──► 可行驶区域分割头
```

BEV 感知的关键优势：相机坐标系与地图坐标系统一，便于与 LiDAR 点云、HD Map 进行坐标对齐融合，消除了传统 2D→3D 转换的累积误差。

### 多传感器融合追踪完整流程

```
┌─────────────────────────────────────────────────────────────┐
│                      感知融合流水线                           │
│                                                             │
│  LiDAR检测结果 ──────────────────────────┐                  │
│  BEV视觉检测结果 ────────────────────────┤                  │
│  毫米波雷达检测结果 ──────────────────────┤                  │
│                                         ▼                  │
│                              数据关联（Hungarian算法）        │
│                                         │                  │
│                              卡尔曼滤波状态更新               │
│                              状态向量：[x, y, z, vx, vy, l, w, h, θ] │
│                                         │                  │
│                              目标ID管理（跨帧一致性）          │
│                                         │                  │
│                              输出：融合目标列表               │
│                              [id, class, bbox, vel, conf]  │
└─────────────────────────────────────────────────────────────┘
```

**时间同步机制：** 各传感器数据戳通过硬件 PPS（Pulse Per Second）信号对齐，多传感器时间同步精度 < 1 ms，确保融合时不因时间差导致目标位置偏移（以 60 km/h 速度行驶，1 ms 时间差对应约 17 mm 位置误差）。


## 高精地图与定位

### 双层地图架构

Apollo 的高精地图采用**双层架构**，分别服务于定位匹配和路径规划两个目的：

| 地图层 | 数据内容 | 数据量 | 更新频率 | 主要用途 |
| --- | --- | --- | --- | --- |
| 点云地图（CloudMap） | 3D LiDAR 扫描点云，密度约 1000点/m² | 约 1 GB/km | 季度级（道路变化后） | LiDAR 实时扫描匹配定位 |
| 矢量 HD Map | 车道几何、信号灯位置、限速标志、坡度、曲率 | 约 10 MB/km | 月度级（人工核验） | 轨迹规划、决策、速度规划 |

矢量 HD Map 采用 OpenDRIVE 格式扩展，包含 **Reference Line（参考线）** 标注，Apollo 规划模块直接在参考线坐标系（Frenet坐标系）下进行轨迹优化，将二维曲线规划转化为沿参考线的 $(s, l)$ 坐标规划。

### NDT 点云定位

Apollo 定位核心采用 **NDT（正态分布变换，Normal Distributions Transform）** 算法进行 LiDAR 点云与预建点云地图的实时匹配：

**NDT 算法原理：**
1. 将点云地图体素化，每个体素内点云建模为高斯分布 $\mathcal{N}(\mu_k, \Sigma_k)$
2. 对于实时扫描中的点 $p_i$，计算其在地图体素中的概率得分：

$$s(\mathbf{T}) = -\sum_{i} \exp\!\left(-\frac{(\mathbf{T} p_i - \mu_k)^\top \Sigma_k^{-1} (\mathbf{T} p_i - \mu_k)}{2}\right)$$

3. 通过牛顿法迭代优化变换矩阵 $\mathbf{T} = (R, t) \in SE(3)$，最大化总概率得分
4. 结合 IMU 预测的初始位姿，通常 3–5 次迭代即收敛

**多传感器融合定位架构：**

$$\hat{x}_t = \text{EKF}(\underbrace{x_{t-1}}_{\text{先验}},\ \underbrace{u_{\text{IMU}}}_{\text{运动模型}},\ \underbrace{z_{\text{NDT}}}_{\text{LiDAR观测}},\ \underbrace{z_{\text{RTK}}}_{\text{GNSS观测}})$$

通过扩展卡尔曼滤波融合 IMU 高频预测（100 Hz）与 NDT 低频更新（10 Hz）、RTK（1–10 Hz），实现 **5–10 cm** 横向定位精度。

### 定位精度指标

| 场景 | 横向精度 | 纵向精度 | 主要影响因素 |
| --- | --- | --- | --- |
| 高速公路（开阔空旷） | 3–5 cm | 5–10 cm | 多径效应低，点云密度高 |
| 城市主干道 | 5–10 cm | 8–15 cm | 动态障碍物干扰点云匹配 |
| 城市峡谷 / 隧道 | 10–20 cm | 15–30 cm | GNSS 信号退化，依赖 IMU 推算 |
| 停车场（室内） | 15–30 cm | 20–40 cm | 无 GNSS，视觉+超声波辅助 |


## 规划模块

Apollo 规划模块（Planning）将定位位姿、HD Map 路由信息、感知目标列表综合处理，输出车辆未来 5–10 秒内的参考轨迹（Reference Trajectory）。

### EM Planner 架构

Apollo 采用 **EM Planner（Expectation-Maximization Planner）** 框架，在 Frenet 坐标系下将轨迹规划分解为**路径优化**和**速度优化**两个互相迭代的子问题：

```
行为决策层（Behavior Decision）
  │  输出：变道/跟车/超车等行为指令
  ▼
路径优化（Path Optimizer）
  │  在 (s, l) 坐标系中规划横向偏移量
  │  目标函数：最小化曲率 + 避障约束 + 车道中心偏离
  ▼
速度优化（Speed Optimizer）
  │  在 ST 图中规划纵向速度剖面
  │  ST图：横轴=时间 t，纵轴=纵向位置 s，障碍物映射为 ST 图中的矩形禁止区
  ▼
轨迹合成（Trajectory Stitch）
  │  路径 × 速度 → (x, y, v, a, t) 时间参数化轨迹
  ▼
输出：轨迹点序列（采样间隔 0.1 s，总时长 5–8 s）
```

### 路径优化数学模型

路径优化在 Frenet 横向坐标 $l(s)$ 上求解：

$$\min_{l(s)} \int_0^S \left[ w_1 l^2 + w_2 \left(\frac{dl}{ds}\right)^2 + w_3 \left(\frac{d^2l}{ds^2}\right)^2 + w_4 \left(\frac{d^3l}{ds^3}\right)^2 \right] ds$$

约束条件：
- 障碍物碰撞约束：$l(s) \notin \mathcal{O}_i(s)$（障碍物投影范围）
- 道路边界：$l_{\min}(s) \leq l(s) \leq l_{\max}(s)$
- 起始点连续性：$l(0) = l_0,\ l'(0) = l'_0$

该问题离散化后转化为**二次规划（QP）** 问题，使用 OSQP 求解器求解，典型求解时间 < 20 ms。

### 速度优化与 ST 图

**ST 图（Space-Time Graph）** 是 Apollo 速度规划的核心工具：

```
纵向位置 s (m)
  ▲
  │         ┌──────┐
  │         │障碍物│  ← 移动障碍物在 ST 图中为斜线矩形
  │    ┌────┘      └────┐
  │    │                │
  │  ──┘                └──  ← 静止障碍物为竖直矩形
  │
  └─────────────────────────► 时间 t (s)
```

速度优化的目标函数：

$$\min_{s(t)} \int_0^T \left[ w_s (\dot{s} - v_{\text{ref}})^2 + w_a \ddot{s}^2 + w_j \dddot{s}^2 \right] dt$$

约束：
- 速度限制：$0 \leq \dot{s}(t) \leq v_{\max}$
- 加速度限制：$a_{\min} \leq \ddot{s}(t) \leq a_{\max}$
- 碰撞约束：$(s(t), t) \notin \mathcal{O}_{\text{ST},i}$（ST图障碍物区域）


## 萝卜快跑商业化数据

百度旗下 Robotaxi 品牌**萝卜快跑（Apollo Go）** 是全球规模最大的 L4 级自动驾驶出行服务，也是百度 Apollo 商业化闭环的核心支点。

### 里程碑事件

- **2020 年**：北京亦庄首批发放 L4 自动驾驶测试牌照，安全员在车
- **2021 年**：上海、广州、长沙相继开城，测试里程超 1000 万公里
- **2022 年**：重庆、武汉获批**主驾无安全员**测试，中国首例
- **2023 年 5 月**：武汉开放副驾无人测试
- **2023 年 8 月**：武汉开放**全无人驾驶**商业收费运营，全球首例城市规模全无人 Robotaxi
- **2024 年**：
  - 运营城市扩展至 **10+ 个**（北京、上海、广州、深圳、武汉、重庆、合肥、成都等）
  - 累计服务订单超 **600 万次**
  - 武汉单日订单峰值超 **2 万单**，引发出租车行业广泛关注
  - 全球累计测试里程超过 **1 亿公里**

### 成本下降路径

| 车型代 | 上市年份 | 单车成本 | 关键降本举措 |
| --- | --- | --- | --- |
| 第三代（Arcfox L4） | 2019 | > 100 万元 | 大量依赖进口 LiDAR（Velodyne），国际供应链 |
| 第四代（红旗 EV） | 2020 | 约 60 万元 | 引入国产 LiDAR（速腾、禾赛），减少传感器数量 |
| 第五代（极狐 αS） | 2021 | 约 48 万元 | 固态 LiDAR 降本，自研感知芯片 |
| RT6（第六代，自研） | 2022 | 约 25 万元 | 双 Orin X 替代多芯异构，全栈自研传感器 |
| 下一代（预计） | 2026 | < 10 万元目标 | 纯固态 LiDAR + 视觉为主，系统进一步集成 |

萝卜快跑的商业模式目标：当单车成本低于 **20 万元**、综合运营成本低于网约车时，实现规模化盈利。


## 开放生态

Apollo 开放平台已构建起涵盖 **210+ 家合作伙伴**的生态系统：

| 合作类型 | 代表机构 / 公司 | 合作内容 |
| --- | --- | --- |
| 整车厂 | 福特、戴姆勒、长安汽车、广汽集团、吉利、一汽红旗 | 车型集成、共同开发 ANP 高速辅助 |
| 零部件供应商 | 博世、大陆集团、法雷奥、均胜电子 | 传感器/线控系统供货，共同验证 |
| 芯片厂商 | 英伟达（Orin X）、英特尔（Mobileye）、地平线（Journey 5） | 计算平台，联合优化模型部署 |
| LiDAR 厂商 | 速腾聚创（RoboSense）、禾赛科技（Hesai）、华为 | 传感器供货，联合标定方案 |
| 地方政府 | 北京亦庄、上海临港、武汉经开区、重庆两江新区 | 测试区域开放，政策先行先试 |
| 学术机构 | 北京大学、清华大学、浙江大学 | 联合研究，算法迭代 |

### 开源贡献

Apollo 核心代码托管于 [github.com/ApolloAuto/apollo](https://github.com/ApolloAuto/apollo)，截至 2024 年已累积：

- **GitHub Stars：** 23,000+
- **代码提交：** 50,000+ commits
- **贡献者：** 500+ 开发者（含百度内部 + 社区）
- **开源模块：** 感知（LiDAR/Camera 检测）、规划（EM Planner）、控制（MPC/LQR）、仿真器（Apollo Sim）、Cyber RT 框架

Apollo 还开放了 **Apollo Studio** 数据标注平台和 **Apollo Cloud** 仿真服务，合作伙伴可直接调用百度云端算力进行模型训练和回放验证。


## Apollo RT6 硬件规格详表

Apollo RT6 是百度 2022 年发布的第六代自动驾驶专用车辆，基于极狐（ARCFOX）纯电动平台改造，面向无人 Robotaxi 商业运营设计：

| 系统类别 | 部件 | 规格参数 | 说明 |
| --- | --- | --- | --- |
| **计算平台** | 主算力芯片 | 2× NVIDIA Orin X（508 TOPS × 2 = 1016 TOPS） | 双芯热备冗余，一颗故障可降级运行 |
| **计算平台** | 辅助安全芯片 | 1× 德州仪器 TDA4 | 功能安全 ASIL-D 监控，独立供电 |
| **激光雷达** | 前向长距 LiDAR | 2× 机械旋转式（128线，200m量程） | 前向目标检测，远距离障碍物识别 |
| **激光雷达** | 侧向/后向 LiDAR | 4× 固态 LiDAR（近场补盲，30m量程） | 车身四角覆盖盲区 |
| **激光雷达** | 顶部全景 LiDAR | 2× 机械式（64线） | 360°环境感知 |
| **摄像头** | 前向摄像头组 | 4×（含 1 长焦 8MP + 2 广角 + 1 鱼眼） | 前向 200m 识别，信号灯检测 |
| **摄像头** | 环视摄像头 | 4× 120°广角鱼眼（2MP） | 泊车、近场全景，BEV 感知 |
| **摄像头** | 侧后视摄像头 | 4× | 变道盲区监控 |
| **毫米波雷达** | 前向中距雷达 | 2×（77 GHz，160m量程） | 远距速度测量，全天候 |
| **毫米波雷达** | 角雷达 | 3×（77 GHz，覆盖侧面+后方） | 侧向碰撞检测，低速安全 |
| **定位** | GNSS 模块 | 双天线 RTK（GPS + 北斗 + Galileo） | 开阔场景 2 cm 精度 |
| **定位** | 惯性导航 | 高精度 IMU（战术级，0.1°/h 漂移） | 高频姿态预测，填补 GNSS 间隙 |
| **通信** | 蜂窝网络 | 5G（Sub-6GHz + mmWave） | 云端 OTA，远程监控 |
| **通信** | 车路协同 | C-V2X（PC5 直连 + Uu 网络） | 路口信号灯信息接收 |
| **冗余安全** | 制动系统 | 双冗余 EPB（电子驻车制动） | 主制动失效时自动触发 |
| **冗余安全** | 转向系统 | 双绕组 EPS（电动助力转向） | 主绕组故障时切换备用 |
| **冗余安全** | 供电 | 双 12V 电源域，独立 UPS | 主电源中断后保持 10 s 安全运行 |
| **整车** | 基础车型 | 极狐 αS（纯电动） | 续航约 600 km（CLTC），无方向盘/踏板版 |
| **整车** | 单车成本 | 约 25 万元 RMB | 较第五代降低约 48% |


## 与竞争对手技术对比

| 维度 | 百度 Apollo / RT6 | Waymo Driver（第六代） | Tesla FSD v12 |
| --- | --- | --- | --- |
| **传感器方案** | LiDAR（8颗）+ Camera（12颗）+ Radar（5颗） | LiDAR（29颗）+ Camera（29颗）+ Radar | 纯视觉（8 Camera，无 LiDAR） |
| **高精地图依赖** | 强（厘米级 HD Map + 点云地图） | 强（Waymo HD Map） | 弱（仅标准导航地图，端到端神经网络） |
| **计算平台** | 双 Orin X（1016 TOPS） | 自研 TPU + Waymo Driver 计算单元 | 自研 FSD Chip（144 TOPS × 2） |
| **定位精度** | 5–10 cm（城市），NDT + RTK 融合 | 5 cm（建图覆盖区） | 车道级（无厘米级，依赖车道检测） |
| **感知范围** | LiDAR 200 m，Camera 200 m | LiDAR 300 m（自研旋转式） | Camera 200 m（视差测距） |
| **商业模式** | Robotaxi 运营（萝卜快跑）+ 赋能主机厂 ANP | Robotaxi 运营（Waymo One，凤凰城/旧金山/洛杉矶） | 软件订阅（FSD，$99/月） |
| **规模化路径** | 降低单车成本，加密城市运营点 | 扩展城市覆盖，深化数据飞轮 | 车队规模数据飞轮（400万+ FSD用户） |
| **中国市场** | 本土绝对领先，10+ 城市商业运营 | 尚未进入中国市场 | 积极推进，2024 年获批部分测试资质 |
| **自动化等级** | L4（无人 Robotaxi） | L4（无安全员商业运营） | L2+（需驾驶员监督） |
| **每公里成本（2024）** | 约 1.4 元（武汉，高峰运营） | 约 $2.5（旧金山，2023 数据） | N/A（用户自有车辆） |


## 参考资料

1. 百度 Apollo. Apollo Platform Technical White Paper, 2023.
2. L. Fan et al. Baidu Apollo EM Motion Planner. arXiv:1807.08048, 2018.
3. 百度萝卜快跑. 2024 年度运营数据报告, 2025.
4. Apollo. Cyber RT: A New Autonomous Driving Framework. Technical Blog, Baidu, 2019.
5. H. Caesar et al. NuScenes: A Multimodal Dataset for Autonomous Driving. CVPR, 2020.（BEV感知基准）
6. J. Zhu et al. BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation. ICRA, 2023.
