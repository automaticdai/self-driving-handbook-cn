# 数据与训练体系：闭环、扩展律与仿真生成

本页关注端到端系统最核心资产：数据与训练流程，从采集闭环到扩展律实践，涵盖合成数据与训练策略。

---

## 1. 数据采集系统架构

### 1.1 车端采集 SDK

高质量数据采集需要精心设计的车端软件栈：

```
┌─────────────────────────────────────────────────────┐
│                  车端采集 SDK                        │
│                                                     │
│  触发策略引擎          ┌─── 事件触发（接管、告警）   │
│  （Trigger Engine）──→ ├─── 区域触发（地理围栏）    │
│                        ├─── 时间采样（周期性）       │
│                        └─── 模型触发（困难样本）     │
│                                                     │
│  数据缓冲区（Ring Buffer）                          │
│  ├─ 传感器原始数据（前向 N 秒 + 后向 M 秒）        │
│  └─ 系统日志（感知/规划/控制输出）                  │
│                                                     │
│  存储管理                                           │
│  ├─ 本地 SSD（高带宽缓冲）                         │
│  └─ 上传队列（按优先级，受带宽限制）                │
└─────────────────────────────────────────────────────┘
```

### 1.2 触发策略设计

| 触发类型 | 触发条件 | 采集窗口 |
| --- | --- | --- |
| 接管事件 | 人工干预自动驾驶 | 触发前 30s + 后 10s |
| 感知低置信度 | 置信度 < 阈值且持续 > 1s | 前 10s + 后 5s |
| 规划失败 | 规划超时或无解 | 前 15s + 后 5s |
| 高风险场景 | TTC < 2s 或急刹 | 前 20s + 后 10s |
| 地理围栏 | 进入标注区域 | 持续采集 |
| 新场景检测 | 模型 embedding 距离大 | 采集 5 分钟 |

### 1.3 数据格式与存储

```
采集包结构（per trigger）：
  manifest.json          # 元数据（时间、位置、触发原因）
  sensors/
    camera_{id}/         # 原始图像（H.265 压缩或 RAW）
    lidar_{id}/          # 点云（PCD 或二进制格式）
    radar_{id}/          # 目标列表
  gnss_imu.bin           # 高频 GNSS/IMU 数据
  system_log.json        # 感知/规划/控制输出
  annotations/           # 自动标注（可选）
```

---

## 2. 场景挖掘技术

### 2.1 基于规则的挖掘

```python
# 挖掘规则示例
rules = [
    {"condition": "min_ttc < 2.0 AND v > 20", "priority": "HIGH"},
    {"condition": "lateral_error > 0.5 AND duration > 3s", "priority": "MEDIUM"},
    {"condition": "pedestrian_density > 5 AND night", "priority": "HIGH"},
]
```

### 2.2 基于模型的困难样本挖掘

**模型不确定性挖掘：**

- **MC Dropout**：多次前向推理，高方差 → 困难样本
- **集成模型**：多模型预测不一致区域
- **损失函数反向**：训练集中损失值高的样本

**Embedding 相似度挖掘：**

```
用预训练 Backbone 提取场景 Embedding
    ↓
在 Embedding 空间聚类（K-Means / FAISS）
    ↓
发现覆盖稀疏的聚类簇（新场景）
    ↓
触发该类场景的主动采集
```

### 2.3 场景聚类与去重

海量数据中存在大量重复场景，去重可大幅提升数据利用效率：

- **感知层去重**：基于场景 Embedding 的近似近邻搜索（FAISS）
- **行为层去重**：轨迹相似度哈希

---

## 3. 数据标注体系

### 3.1 标注层级

| 标注类型 | 成本 | 自动化程度 | 典型用途 |
| --- | --- | --- | --- |
| 传感器同步原始数据 | 低 | 100% 自动 | 模型输入 |
| 3D 框标注 | 高 | 半自动（人工验收） | 感知监督 |
| 轨迹标注 | 中 | 半自动（插值+修正） | 预测/规划监督 |
| 语义分割 | 很高 | 半自动 | 感知训练 |
| 场景标签 | 低 | 规则自动 | 数据配比 |

### 3.2 自动标注流程（Auto-Labeling）

```
原始数据
    │
    ↓ 使用最强版本的离线模型（Teacher Model）推理
粗标注结果
    │
    ↓ 基于置信度阈值过滤（低置信度送人工）
高质量自动标注
    │
    ↓ 人工质检（抽查比例 5%–20%）
最终标注
```

使用强模型（更多算力、更大分辨率）生成标注，再训练车端轻量模型（知识蒸馏）。

---

## 4. 扩展律（Scaling Law）实践

### 4.1 数据-性能关系

Scaling Law 描述数据量、模型参数量与性能的幂律关系：

$$\mathcal{L}(D, N) \approx A \cdot D^{-\alpha} + B \cdot N^{-\beta} + C$$

其中 $D$ 为数据量，$N$ 为模型参数量，$\alpha, \beta$ 为幂律指数，通常约为 0.3–0.5。

!!! note "有效数据密度"
    盲目增加数据量效果有限。**有效数据密度**（Effective Data Diversity）比总量更重要：100 万张日常工况数据的价值可能不如 10 万张长尾场景数据。

### 4.2 实践经验

| 资源投入 | 预期收益 | 边际效益 |
| --- | --- | --- |
| 数据量翻倍 | 错误率降低 10–30% | 递减 |
| 模型容量翻倍 | 错误率降低 5–20% | 递减 |
| 算力翻倍（训练更久） | 可能 5–15% 提升 | 递减 |
| 长尾数据 10× | 长尾场景指标大幅提升 | 高价值 |

---

## 5. 合成数据生成

### 5.1 传感器仿真

| 方法 | 效果 | 成本 |
| --- | --- | --- |
| 渲染引擎（Unreal/Unity）| 视觉逼真，物理准确 | 搭建成本高 |
| NeRF 重建 | 从真实数据重建场景，高保真 | 推理慢 |
| 3DGS（高斯溅射）| 实时渲染，质量高 | 相对新，工具链不成熟 |
| 点云仿真 | 从 CAD 模型生成点云 | 精度受模型质量影响 |

### 5.2 合成数据的主要用途

1. **危险场景补充**：无法在真实道路采集的场景（高速碰撞前序、逃跑行为）
2. **天气/光照扩展**：将晴天数据风格迁移为雨天、夜间
3. **长尾类别扩充**：摩托车、特种车辆、轮椅等稀有类别
4. **传感器故障仿真**：相机模糊、LiDAR 噪声模拟

---

## 6. 数据配比策略

### 6.1 配比原则

```python
# 训练数据配比示例
dataset_config = {
    "normal_driving": {
        "weight": 0.4,    # 日常工况，保证分布稳定
        "sample_strategy": "uniform"
    },
    "long_tail": {
        "weight": 0.4,    # 长尾场景，提高采样权重
        "sample_strategy": "importance_weighted"
    },
    "synthetic": {
        "weight": 0.2,    # 合成数据，补齐危险场景
        "sample_strategy": "uniform"
    }
}
```

### 6.2 课程学习（Curriculum Learning）

先从简单样本开始训练，逐步引入困难样本：

```
阶段 1（Epoch 1-10）：  简单场景（直道、清晰天气、少障碍）
阶段 2（Epoch 11-30）：  中等场景（弯道、多障碍、变道）
阶段 3（Epoch 31-60）：  困难场景（长尾场景、合成危险）
```

---

## 7. 训练策略

### 7.1 多任务学习

端到端模型联合优化多个任务：

$$\mathcal{L}_{\text{total}} = \lambda_1 \mathcal{L}_{\text{perception}} + \lambda_2 \mathcal{L}_{\text{prediction}} + \lambda_3 \mathcal{L}_{\text{planning}}$$

任务权重 $\lambda_i$ 通常通过 Uncertainty Weighting 或人工调优。

### 7.2 知识蒸馏

将大模型（Teacher）的知识迁移到小模型（Student）：

**软标签蒸馏：**

$$\mathcal{L}_{\text{KD}} = \alpha \cdot \mathcal{L}_{\text{CE}}(y, \hat{y}) + (1-\alpha) \cdot T^2 \cdot \text{KL}\left(\sigma\left(\frac{z_T}{T}\right) \| \sigma\left(\frac{z_S}{T}\right)\right)$$

**特征蒸馏：** 让学生模型中间层特征接近教师模型，保留更多知识。

### 7.3 分布式训练

| 并行策略 | 适用场景 | 通信开销 |
| --- | --- | --- |
| 数据并行（DP） | 大数据集，模型可单卡放下 | 梯度同步（带宽密集） |
| 模型并行（MP） | 超大模型，单卡放不下 | 激活值传输 |
| 流水线并行（PP） | 超大模型 + 高吞吐 | 流水线气泡 |
| ZeRO 优化 | 大模型 + 高利用率 | DeepSpeed 框架 |

---

## 8. 训练数据版本管理

### 8.1 版本化工具

- **DVC（Data Version Control）**：Git 风格管理大文件
- **MLflow**：实验跟踪（超参数、指标、模型版本）
- **Weights & Biases（W&B）**：训练可视化与对比

### 8.2 数据集版本规范

```yaml
dataset_version: "v2.5.0"
created_date: "2025-03-01"
total_clips: 150000
composition:
  normal: 60000      # 日常工况
  long_tail: 70000   # 长尾场景
  synthetic: 20000   # 合成数据
split:
  train: 0.8
  val: 0.1
  test: 0.1          # 测试集永不用于训练
changes_from_v2.4: "新增夜间雨天场景 15000 条"
```

---

## 9. 工程注意点

| 注意项 | 说明 |
| --- | --- |
| 测试集隔离 | 测试集严格不参与训练或超参调整，模拟真实上线效果 |
| 时序相关性 | 视频片段在切分时应确保 Train/Val/Test 不跨同一行程 |
| 标注一致性检验 | 定期对同一样本做多轮标注，计算 Kappa 系数 |
| 关键标签抽检 | 对接管、碰撞、违规类标签 100% 人工核查 |
| 数据安全 | 行程数据脱敏（人脸模糊、车牌打码）再上云存储 |
