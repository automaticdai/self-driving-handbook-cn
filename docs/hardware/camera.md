# 视觉传感器（摄像头）

摄像头是自动驾驶感知系统的核心传感器。相比激光雷达和毫米波雷达，摄像头具有成本低、信息密度高的显著优势——单颗图像传感器即可同时获取颜色、纹理、形状和语义信息，非常适合交通标志识别、车道线检测、目标分类等需要语义理解的任务。以特斯拉为代表的纯视觉自动驾驶方案证明，在算法足够强大的前提下，摄像头阵列可以成为整个感知体系的基础。


## 1. 摄像头光学基础

### 1.1 小孔成像模型

摄像头最常用的数学模型是**小孔相机模型（Pinhole Camera Model）**。三维空间中的点 $P = (X, Y, Z)$ 经过光心投影到像平面上的点 $p = (x, y)$，满足：

$$x = f \cdot \frac{X}{Z}, \quad y = f \cdot \frac{Y}{Z}$$

其中 $f$ 为焦距（单位：像素或毫米）。将像素坐标系与主点偏移结合，得到完整的像素坐标：

$$u = f_x \cdot \frac{X}{Z} + c_x, \quad v = f_y \cdot \frac{Y}{Z} + c_y$$

### 1.2 相机内参矩阵

上述投影关系可以用齐次坐标写成矩阵形式：

$$\begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \frac{1}{Z} K \begin{bmatrix} X \\ Y \\ Z \end{bmatrix}$$

其中**内参矩阵（Intrinsic Matrix）** $K$ 定义为：

$$K = \begin{bmatrix} f_x & 0 & c_x \\ 0 & f_y & c_y \\ 0 & 0 & 1 \end{bmatrix}$$

- $f_x, f_y$：水平/垂直方向的焦距（像素为单位，$f_x = f / s_x$，$s_x$ 为像素水平尺寸）
- $(c_x, c_y)$：主点（Principal Point），通常接近图像中心
- 若像素为正方形（$f_x = f_y$），则只需一个焦距参数

### 1.3 视场角（FOV）

视场角描述摄像头的可视范围，由焦距 $f$ 与传感器尺寸 $d$ 共同决定：

$$\theta = 2\arctan\!\left(\frac{d}{2f}\right)$$

其中 $d$ 对应水平方向时得到**水平FOV**，对应垂直方向时得到**垂直FOV**，对应对角线时得到**对角FOV**。

实际车载摄像头的焦距选择遵循以下原则：

| 焦距类型 | 典型水平FOV | 适用场景 |
| --- | --- | --- |
| 长焦（如 12 mm） | 约 30°–50° | 远端目标检测（>100 m），高速公路 |
| 中焦（如 6 mm） | 约 60° | 综合感知，城市道路 |
| 广角（如 2.5 mm） | 约 100°–120° | 近场覆盖，交叉路口，变道辅助 |
| 鱼眼（如 1.3 mm） | 约 180°–195° | 泊车环视，盲区覆盖 |

### 1.4 景深与光圈

**景深（Depth of Field, DoF）**是指图像中清晰成像的距离范围，由光圈（F值）、焦距和对焦距离共同决定：

$$\text{DoF} \approx \frac{2 N c f^2 d}{f^4 - N^2 c^2 d^2}$$

其中 $N$ 为光圈F值，$c$ 为弥散圆直径，$d$ 为对焦距离。车载摄像头通常使用较大光圈（F1.6–F2.0）以保证低照度性能，同时固定对焦于超焦距以获得最大景深，无需动态对焦机构。


## 2. 图像传感器

### 2.1 CMOS vs CCD

| 对比维度 | CMOS | CCD |
| --- | --- | --- |
| 读取方式 | 每个像素独立放大读出 | 电荷逐行转移读出 |
| 速度 | 高（可局部读取） | 较低 |
| 功耗 | 低 | 高（约CMOS的10倍） |
| 集成度 | 高（ADC/ISP可片上集成） | 低（需外部电路） |
| 噪声 | 固定图案噪声稍高 | 均匀性好，暗电流低 |
| 成本 | 低 | 高 |
| 车载应用 | 主流选择 | 基本已淘汰 |

目前车载图像传感器几乎全部采用CMOS工艺，主流厂商包括索尼（Sony）、安森美（onsemi）、豪威（OmniVision）等。

### 2.2 卷帘快门（Rolling Shutter）

卷帘快门的曝光方式是**逐行依次曝光**，各行之间存在时间差。当拍摄运动目标或相机自身运动时，会产生以下伪影：

- **果冻效应（Jello Effect）**：快速横向运动导致垂直边缘倾斜
- **运动模糊不一致**：图像上下部分的运动状态不同步
- **闪光带（Flash Banding）**：在频闪光源下出现横向亮暗条纹

在ADAS场景中，车辆高速行驶时卷帘快门会导致测距误差。例如，以 $v = 30\ \text{m/s}$ 的速度行驶，帧读出时间为 $16\ \text{ms}$，则图像顶部与底部的位置差可达 $0.48\ \text{m}$，对检测精度影响显著。

### 2.3 全局快门（Global Shutter）

全局快门对所有像素**同时开始和结束曝光**，完全消除因逐行读出引起的运动伪影，是高速运动场景的必选方案。代价是像素面积利用率（Fill Factor）较低，在相同工艺下感光度略逊于卷帘快门。

车载应用中：
- **前视远焦摄像头**：通常要求全局快门，以保证高速行驶时的目标检测精度
- **环视鱼眼摄像头**：低速泊车场景，卷帘快门可接受
- **DMS内舱摄像头**：检测眨眼/头部转动等高频动作，推荐全局快门

### 2.4 像素尺寸与低光性能

像素物理尺寸越大，单位时间内收集的光子数越多，信噪比越高。常见像素尺寸：

- 手机摄像头：0.6–1.0 µm
- 车载摄像头：2.0–4.0 µm（索尼 IMX490：3.0 µm）

像素尺寸与信噪比的近似关系：像素面积增大4倍，暗场信噪比提升约6 dB。

### 2.5 高动态范围（HDR）

自动驾驶场景需要同时看清隧道出口的强光区和隧道内的阴暗区，要求传感器**动态范围（Dynamic Range）**超过120 dB，而普通CMOS只有约60–70 dB。

常见HDR实现方式：

- **双曝光合并（Dual Exposure）**：同一帧内采用长短两次曝光，分别捕获暗部和亮部，再合并为HDR图像
- **多曝光交织（Multi-Exposure Interleaving）**：连续帧交替使用不同曝光时间
- **分区像素HDR（Lateral Overflow Integration Capacitor, LOFIC）**：像素内集成两个电容，分别存储高/低增益信号
- **Log域传感器**：像素响应曲线为对数型，天然压缩高光

索尼 IMX490 采用 DOL-HDR（Digital Overlap HDR）技术，可实现 120 dB 动态范围，是目前车载摄像头的主流选择。


## 3. ISP图像信号处理管线

原始传感器输出的**RAW数据**（拜尔格式，Bayer Pattern）需要经过图像信号处理器（ISP）的一系列处理才能转换为可用图像。

### 3.1 ISP处理流程

```
传感器RAW输出（Bayer格式）
        │
        ▼
┌─────────────────────┐
│  黑电平校正          │  Black Level Correction
│  (减去暗电流偏置)    │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  镜头阴影校正        │  Lens Shading Correction (LSC)
│  (补偿边缘暗角)      │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  去拜尔/插值         │  Demosaicing / Debayering
│  (RGGB → RGB)       │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  自动白平衡          │  Auto White Balance (AWB)
│  (色温校正)         │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  色彩校正矩阵        │  Color Correction Matrix (CCM)
│  (传感器色域→sRGB)   │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  时域/空域去噪       │  Temporal NR + Spatial NR
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  Gamma校正          │  Gamma Correction
│  (线性→感知均匀)    │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  图像压缩/输出       │  H.264 / H.265 / RAW
└─────────────────────┘
```

### 3.2 各处理步骤说明

**去拜尔（Demosaicing）**：传感器使用拜尔滤色阵列（RGGB），每个像素只感知一种颜色。去拜尔算法通过插值恢复每个像素的完整RGB值，常用方法有双线性插值、自适应同色细节保持（AHDHA）等。

**黑电平校正（Black Level Correction）**：传感器即使在完全遮光情况下也会输出非零的暗电流信号，需减去该基准值以保证黑色真正为零。

**镜头阴影校正（Lens Shading Correction, LSC）**：镜头边缘进光量少于中心，导致图像四角变暗（Vignetting）。LSC通过查找表对每个像素施加位置相关的增益补偿。

**去噪（Noise Reduction）**：
- **空域降噪（Spatial NR）**：在单帧内利用相邻像素相关性平滑噪声，如双边滤波（Bilateral Filter）
- **时域降噪（Temporal NR）**：跨帧对齐后加权平均，对静止背景去噪效果极佳，但运动区域需谨慎处理

**白平衡（AWB）**：在不同色温光源（晴天 5500K / 阴天 6500K / 钨灯 3200K）下，白色物体在传感器上的R/G/B响应不同。AWB计算增益系数使白色物体的输出接近理想白色。

**色彩校正矩阵（CCM）**：传感器的光谱响应与标准色空间（sRGB）不完全匹配，通过3×3矩阵线性变换进行校正：

$$\begin{bmatrix} R' \\ G' \\ B' \end{bmatrix} = \begin{bmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{bmatrix} \begin{bmatrix} R \\ G \\ B \end{bmatrix}$$

**Gamma校正**：人眼对亮度的感知是非线性的（对暗部更敏感），Gamma编码将线性光信号压缩为感知均匀的编码值，减少编码位数需求。sRGB标准使用 $\gamma \approx 2.2$：

$$V_{out} = V_{in}^{1/\gamma}$$

**图像压缩**：
- **H.264/H.265**：有损视频压缩，适合录像和远程传输，帧间预测大幅降低码率
- **RAW输出**：保留原始传感器数据，供后端算法进行自定义ISP处理，占用带宽大（通常需要SerDes链路）


## 4. 镜头畸变与标定

### 4.1 径向畸变（Radial Distortion）

径向畸变是最主要的镜头畸变类型，由镜片曲率不完美导致。以主点为原点，设无畸变像点为 $(x, y)$，畸变后的像点为 $(x', y')$，径向畸变模型为：

$$x' = x(1 + k_1 r^2 + k_2 r^4 + k_3 r^6 + \cdots)$$
$$y' = y(1 + k_1 r^2 + k_2 r^4 + k_3 r^6 + \cdots)$$

其中 $r^2 = x^2 + y^2$，$k_1, k_2, k_3$ 为径向畸变系数。

- **桶形畸变（Barrel Distortion）**：$k_1 < 0$，图像向中心收缩，广角镜头常见
- **枕形畸变（Pincushion Distortion）**：$k_1 > 0$，图像向外膨胀，长焦镜头常见

### 4.2 切向畸变（Tangential Distortion）

切向畸变由镜片与传感器平面不完全平行引起：

$$x' = x + [2p_1 xy + p_2(r^2 + 2x^2)]$$
$$y' = y + [p_1(r^2 + 2y^2) + 2p_2 xy]$$

其中 $p_1, p_2$ 为切向畸变系数。通常 $p_1, p_2$ 远小于 $k_1$，在精度要求不高时可忽略。

### 4.3 棋盘格标定法（Zhang's Method）

张正友标定法是目前最广泛使用的相机标定方法，无需精密三维标定靶，仅使用平面棋盘格即可标定内参和畸变系数。

标定流程：
1. 打印或显示已知尺寸的棋盘格图案（如 $9 \times 6$ 内角点）
2. 从不同角度和距离采集 15–30 张图像
3. 使用角点检测算法（如 Harris 角点、亚像素细化）提取图像中的棋盘格角点坐标 $\{m_i\}$
4. 建立世界坐标 $\{M_i\}$ 与图像坐标的对应关系，通过最小化重投影误差求解参数：

$$\min_{K, k_1, k_2, p_1, p_2} \sum_i \sum_j \left\| m_{ij} - \hat{m}(K, k_1, k_2, p_1, p_2, R_i, t_i, M_j) \right\|^2$$

5. 使用 Levenberg-Marquardt 算法进行非线性优化
6. 标定精度评估：重投影误差（Reprojection Error）通常要求小于 0.5 个像素

### 4.4 鱼眼镜头等距投影模型

普通针孔模型不适用于FOV超过150°的鱼眼镜头，需使用等距投影（Equidistant Projection）或等立体角投影（Equisolid Angle）模型：

**等距投影**：

$$r = f \cdot \theta$$

其中 $r$ 为像点到主点的距离，$\theta$ 为入射光线与光轴的夹角。鱼眼标定常用 OpenCV 的 `fisheye` 模块，畸变系数为 $k_1, k_2, k_3, k_4$。

### 4.5 多相机外参标定

自动驾驶车辆通常配备多个摄像头，需要标定各摄像头相对于车体坐标系（或某一基准传感器）的外参——即刚体变换矩阵：

$$T_{cam \to body} = \begin{bmatrix} R & t \\ 0 & 1 \end{bmatrix} \in SE(3)$$

其中 $R \in SO(3)$ 为旋转矩阵（3个自由度），$t \in \mathbb{R}^3$ 为平移向量。

多相机外参标定方法：
- **使用大型平面靶板**：多个摄像头同时观测同一靶板，通过优化各摄像头的相对姿态
- **使用三维特征点**：在环境中放置已知三维坐标的标定点（如AprilTag），各摄像头独立定位后求相对变换
- **在线联合标定**：利用运动中的自然特征点（车道线、建筑边缘），通过束调整（Bundle Adjustment）在线优化外参


## 5. 车载摄像头类型对比

### 5.1 各类型摄像头说明

**前视摄像头（Forward Camera）**：

特斯拉的三目前视方案（前主摄/前广角/前远摄）代表了行业最佳实践：
- **前远摄（Narrow）**：FOV约 25°，焦距约 12 mm，最远感知距离 >250 m，用于高速公路跟车和目标预判
- **前中摄（Main）**：FOV约 52°，覆盖主要前向感知区域，用于目标检测和车道线识别
- **前广角（Wide）**：FOV约 120°，用于交叉路口和低速跟车场景

**环视鱼眼摄像头（Surround View Camera）**：

四路鱼眼摄像头布置于车辆前后左右，每路FOV约 185°–195°，通过图像拼接和俯视变换生成鸟瞰图（BEV），主要用于自动泊车和低速辅助驾驶。

**后视摄像头（Rear Camera）**：

布置于车辆尾部，FOV约 130°–140°，中焦或广角，用于倒车辅助和后方来车检测。部分法规（如美国FMVSS 111）强制要求安装。

**内舱DMS摄像头（Driver Monitoring System Camera）**：

监测驾驶员疲劳、注意力分散和头部姿态。使用**近红外（NIR）摄像头**（850 nm 或 940 nm 波长），配合红外补光灯，可在强光和黑暗环境下工作，不受驾驶员佩戴太阳镜影响。

### 5.2 车载摄像头规格对比表

| 类型 | 水平FOV | 典型焦距 | 分辨率 | 快门 | 主要应用 |
| --- | --- | --- | --- | --- | --- |
| 前视远焦 | 25°–35° | 10–16 mm | 8 MP | 全局快门 | 远距目标检测，>150 m |
| 前视中焦 | 50°–60° | 6–8 mm | 8 MP | 全局快门 | 综合前向感知 |
| 前视广角 | 100°–120° | 2.5–4 mm | 2–3 MP | 卷帘/全局 | 近场交叉路口覆盖 |
| 环视鱼眼 | 180°–195° | 1.2–1.8 mm | 3–5 MP | 卷帘快门 | 泊车，BEV拼接 |
| 后视摄像头 | 130°–140° | 2–3 mm | 2–3 MP | 卷帘快门 | 倒车辅助 |
| DMS摄像头 | 80°–100° | 3–4 mm | 1–2 MP | 全局快门 | 驾驶员状态监测 |


## 6. 主流车载摄像头产品

### 6.1 图像传感器（Sensor Die）

**索尼（Sony）IMX系列**

索尼是全球车载图像传感器的领导者，主要车规级产品：
- **IMX490**：1/2.5 英寸，5.4 MP，3.0 µm像素，全局快门，DOL-HDR 120 dB，支持车规（AEC-Q100 Grade 2）
- **IMX728**：1/1.7 英寸，8.3 MP，2.5 µm像素，全局快门，适用于高分辨率前视应用

**安森美（onsemi）AR系列**

- **AR0820CS**：1/2 英寸，8.3 MP，2.1 µm像素，卷帘/全局快门可选，三曝光HDR，适合L2+前视摄像头
- **AR0233**：2.3 MP，全局快门，低功耗，适合ADAS入门级应用

**豪威科技（OmniVision）**

- **OX08B40**：8 MP，车规级，支持DOL-HDR，广泛用于中端自动驾驶平台

**韦尔半导体（Will Semi / OmniVision）**

韦尔半导体通过收购豪威科技成为中国最大的图像传感器设计公司，积极拓展车载市场，其CMOS传感器产品已进入多家国内整车厂供应链。

### 6.2 摄像头模组（Camera Module）

| Tier1模组厂商 | 代表产品 | 特点 |
| --- | --- | --- |
| 舜宇光学（Sunny Optical） | SV系列车载模组 | 中国最大光学镜头企业，出货量全球领先 |
| 联创电子（LianChuang） | 多款前视/环视模组 | 专注车载摄像头，客户包括比亚迪、蔚来等 |
| Sekonix（韩国） | SF3324/SF3325 | NVIDIA Jetson/DRIVE平台官方推荐 |
| Continental（德国大陆） | MFC5xx系列 | 集成ISP和SoC，Tier1一体化前视模组 |
| Aptiv（安波福） | 多款ADAS摄像头 | 与Mobileye紧密合作，主供欧美OEM |

### 6.3 主流产品规格对比

| 产品型号 | 传感器 | 分辨率 | 动态范围 | 快门 | 接口 |
| --- | --- | --- | --- | --- | --- |
| 索尼 IMX490 | 索尼 | 5.4 MP | 120 dB | 全局 | MIPI CSI-2 |
| 索尼 IMX728 | 索尼 | 8.3 MP | 100 dB | 全局 | MIPI CSI-2 |
| 安森美 AR0820CS | 安森美 | 8.3 MP | 120 dB | 全局/卷帘 | MIPI CSI-2 |
| OmniVision OX08B | 豪威 | 8 MP | 120 dB | 卷帘 | MIPI CSI-2 |
| Sekonix SF3325 | AR0231AT | 2.1 MP | 100 dB | 全局 | GMSL2 |


## 7. 摄像头时序同步

多传感器融合的前提是各传感器数据在时间上严格对齐。摄像头与激光雷达、IMU之间的时间不同步会导致运动目标位置估计错误，是系统设计的关键挑战。

### 7.1 硬件触发同步

最可靠的摄像头同步方式是**硬件触发**：

1. 主控（Domain Controller）或专用时序控制器产生**Trigger信号**（GPIO脉冲）
2. 脉冲的上升沿（或下降沿）触发所有摄像头同时开始曝光
3. 各摄像头的曝光中心时刻相同，消除帧间的相对时间差

对于多路摄像头（如8路360°摄像头阵列），所有Trigger信号应从同一时钟源派生，并考虑线缆传输延迟的补偿（通常 $<10\ \text{ns}$）。

### 7.2 与LiDAR的时间对齐

激光雷达通常以固定频率（如10 Hz或20 Hz）旋转扫描，每圈扫描的起始时刻由内部时钟决定。与摄像头对齐需要：

1. **PPS脉冲（Pulse Per Second）**：GPS接收机或时钟模块每秒输出一个高精度脉冲，精度可达 $<1\ \mu\text{s}$
2. **IEEE 1588 PTP（Precision Time Protocol）**：通过以太网实现纳秒级时间同步，各节点（摄像头SoC、LiDAR控制器、ECU）锁定到同一时钟
3. **时间戳注入（Timestamp Injection）**：在摄像头曝光中心时刻记录精确时间戳，与LiDAR点云的时间戳对应，用于数据融合时的插值对齐

典型时间同步精度要求：对于100 km/h行驶速度，1 ms的时间误差对应约2.8 cm的位置误差，多数系统要求时间同步精度优于 $\pm 0.5\ \text{ms}$。

### 7.3 帧率选择（30 fps vs 60 fps）

| 对比项 | 30 fps | 60 fps |
| --- | --- | --- |
| 帧间距 | 33.3 ms | 16.7 ms |
| 高速场景（100 km/h）帧间位移 | ~92 cm | ~46 cm |
| 带宽需求 | 基准 | 约2倍 |
| 功耗 | 低 | 高（约30–50%增加） |
| ISP处理需求 | 低 | 高 |
| 适用场景 | L2级ADAS，大多数城市场景 | L3+高速场景，高精度目标跟踪 |

实际工程中，前视远焦摄像头（高速行驶）通常使用60 fps，环视鱼眼（低速泊车）使用30 fps，以平衡性能与系统带宽。


## 参考资料

1. Zhang, Z. "A Flexible New Technique for Camera Calibration." *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 22(11):1330–1334, 2000.
2. Szeliski, R. *Computer Vision: Algorithms and Applications*, 2nd ed. Springer, 2022. Chapter 2: Image Formation.
3. Sony Semiconductor Solutions. *IMX490 Product Brief: Automotive CMOS Image Sensor*. 2022.
4. Tesla AI Day. "Tesla Vision & Occupancy Networks." Presentation, 2021. https://tesla.com/AI
5. AUTOSAR. *Specification of Camera ISP Driver*. Release 4.4.0, 2019. https://www.autosar.org
