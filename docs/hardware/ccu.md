# 中央计算单元 (CCU / 车载AI芯片)

自动驾驶系统需要在毫秒级时间窗口内完成"感知—理解—决策—控制"的完整闭环，这一切依赖中央计算单元（Central Computing Unit，CCU）提供的强大算力支撑。CCU 是自动驾驶汽车的"大脑"，其算力规模、实时响应能力与功能安全等级共同决定了智能驾驶的能力上限。从 L2 辅助驾驶的数十 TOPS，到 L4 无人驾驶所需的数百乃至数千 TOPS，算力需求正以指数级增长，推动着车载计算芯片持续演进。


## 1. 处理器类型对比

现代自动驾驶计算平台并非依赖单一处理器，而是将多种异构计算单元集成于同一 SoC 或计算板卡，各司其职、协同运作。

### 1.1 CPU（通用处理器）

CPU 擅长顺序执行、分支判断与操作系统调度，是整个计算平台的"总指挥"。车规级 CPU 通常采用 ARM Cortex-R 系列（实时处理）或 ARM Cortex-A 系列（高性能应用）。

- **Cortex-R 系列**：具有硬实时特性，中断响应时间可低至微秒级，适用于制动、转向等安全关键控制任务。
- **Cortex-A 系列**（如 A78AE）：支持运行 Linux / Hypervisor，负责系统管理、路径规划算法（如 A*、RRT）、V2X 通信协议栈处理等非实时或软实时任务。
- "AE"（Automotive Enhanced）版本支持硬件拆分模式（Split Lock），一颗物理核心可在两个隔离分区中独立运行，满足 ASIL-B/D 安全需求。

### 1.2 GPU（图形处理单元）

GPU 含有数千至数万个轻量级着色器核心，擅长对大规模数据进行相同操作的并行计算（SIMD/SIMT 模式），天然匹配深度学习推理中的矩阵乘法与卷积运算。

- 车载 GPU 通常采用 CUDA 架构（NVIDIA）或 GPU 计算单元（高通 Adreno 等）。
- 主要承担：多路摄像头实时感知模型推理、BEV（鸟瞰图）特征提取、3D 目标检测。
- 相比 CPU，GPU 在同等功耗下处理深度学习任务的吞吐量高出 10～100 倍。

### 1.3 NPU / DLA（神经网络处理单元 / 深度学习加速器）

NPU/DLA 是专为神经网络推理设计的固定功能加速器，硬件电路固化了矩阵乘法、激活函数、批归一化等常见算子。

- 能效比（TOPS/W）通常是 GPU 的 3～10 倍，非常适合车载功耗受限场景。
- 局限性：灵活性低，对非标准算子（如自定义注意力机制）支持较差，需提前编译模型至专用格式（如 ONNX → TensorRT Engine 或厂商私有格式）。
- 典型实现：NVIDIA DLA v2.0（Orin 内置 × 2）、地平线 BPU、Tesla NPU。

### 1.4 FPGA（现场可编程门阵列）

FPGA 通过可重配置逻辑门阵列实现硬件级并行，延迟极低（纳秒级），支持运行时重新编程。

- 主要应用于传感器数据预处理：LiDAR 点云解码与过滤、雷达原始信号 FFT、摄像头 ISP 流水线加速。
- 量产车中较少独立部署 FPGA 计算板，但部分 SoC 内置专用硬件加速器，其设计理念与 FPGA 相近。
- 代表方案：赛灵思 (AMD Xilinx) Versal 系列，集成 ARM CPU + FPGA LUT + AI Engine。

### 1.5 ASIC（专用集成电路）

ASIC 是为特定算法量身定制的芯片，在功耗、面积和性能上全面优化，代价是完全丧失灵活性。

- **Tesla D1 训练芯片**：专为神经网络训练设计，单芯片 362 TFLOPS（BF16），64 颗 D1 组成 Dojo Training Tile，算力达 1.1 PFLOPS，用于离线训练 FSD 视频推理模型。
- **Mobileye EyeQ** 系列：高度定制的图像处理 ASIC，集成专用视觉加速核心，超低功耗（< 15W）实现 L2+ 功能。

### 1.6 处理器类型综合对比

| 处理器类型 | 灵活性 | AI 算力 | 功耗效率 | 单位成本 | 开发难度 | 典型应用场景 |
|-----------|--------|---------|----------|----------|----------|------------|
| CPU        | ★★★★★ | ★★      | ★★       | ★★★      | ★        | 系统调度、路径规划 |
| GPU        | ★★★★  | ★★★★   | ★★★      | ★★       | ★★       | 感知推理、BEV 特征提取 |
| NPU/DLA   | ★★     | ★★★★★  | ★★★★★   | ★★★★     | ★★★★     | 固定神经网络推理 |
| FPGA       | ★★★★  | ★★★     | ★★★★    | ★        | ★★★★★   | 传感器预处理、低延迟逻辑 |
| ASIC       | ★      | ★★★★★  | ★★★★★   | ★★★★★   | ★★★★★   | 量产专用加速（训练/推理） |

（★越多代表该维度越强；成本★越多代表成本越低）


## 2. 主流自动驾驶 SoC 详解

### 2.1 NVIDIA Orin（AGX Orin / Drive Orin）

- **制程**：12nm（三星）
- **AI 算力**：254 TOPS（INT8）
- **CPU**：12 核 ARM Cortex-A78AE
- **GPU**：2048 核 Ampere 架构 GPU
- **DLA**：2 × NVDLA v2.0（专用深度学习加速器）
- **ISP/PVA**：支持最多 16 路摄像头输入，内置可编程视觉加速器（PVA）
- **内存**：最大 64 GB LPDDR5，内存带宽 204 GB/s
- **功耗**：45 W（典型），最大 60 W
- **量产客户**：理想汽车（AD Max 平台，双 Orin）、蔚来 ET7/ES7、小鹏 G9/P7i、比亚迪海豹 DM-i 等
- **特点**：CUDA/TensorRT 生态完整，支持多芯片 NVLink 级联；具备硬件虚拟化，可同时运行 QNX 安全域与 Linux 功能域。

### 2.2 NVIDIA Thor

- **制程**：4nm（台积电 N4）
- **AI 算力**：2000 TOPS（单芯片）
- **GPU**：Blackwell 架构，支持 FP8 推理
- **目标场景**：L4/L5 完全自动驾驶，中央计算架构（将座舱与驾驶计算合并）
- **接口**：支持以太网 TSN、PCIe Gen5、DisplayPort 2.1
- **发布时间**：2025 年量产车型预计首发搭载
- **特点**：相比 Orin 算力提升近 8 倍，支持端到端大模型在车端实时推理。

### 2.3 Tesla FSD Chip（HW3，硬件三代）

- **制程**：14nm（三星）
- **AI 算力**：144 TOPS（双芯片合计 288 TOPS）
- **CPU**：12 核 ARM A72
- **GPU**：Mali G71 MP12（主要用于显示）
- **NPU**：2 × 自研 NNA（Neural Network Accelerator），每颗支持 72 TOPS
- **功耗**：72 W（整个计算硬件）
- **存储**：LPDDR4，内存带宽 68 GB/s
- **设计亮点**：双 SoC 热备冗余（两颗独立运行，互相监控输出），自研 NPU 对 Tesla 特有卷积网络高度优化
- **应用范围**：Autopilot / FSD Beta，仅支持摄像头视觉方案（无雷达、无激光雷达）

### 2.4 Tesla AI5（HW4）

- **AI 算力**：300+ TOPS（具体数据未完全公开）
- **摄像头支持**：支持 5MP 高分辨率摄像头（HW3 为 1.2MP）
- **制程**：据报道采用台积电 7nm 以下制程
- **量产时间**：2023 年下半年开始搭载于 Model S/X/3/Y 改款
- **特点**：算力大幅提升，为 FSD V12 端到端神经网络架构（视频级输入直接输出控制量）提供支撑。

### 2.5 Mobileye EyeQ6（High / Low）

- **制程**：7nm（台积电）
- **AI 算力**：EyeQ6H：34 TOPS；EyeQ6L：10 TOPS
- **功耗**：EyeQ6H < 15 W；EyeQ6L < 5 W
- **架构**：多核 MIPI VMP（Vector Microcode Processor）+ 标量处理器 + 深度学习加速核心
- **软件闭环**：Mobileye 采用完整软硬件垂直整合模式，仅开放有限 API 给主机厂
- **量产客户**：宝马、通用、Stellantis 等，搭载于 SuperVision 辅助驾驶系统
- **特点**：极低功耗、符合严苛车规要求，适合无独立散热设计的车型

### 2.6 Mobileye Chauffeur（L4 平台）

- **架构组成**：EyeQ6H × 2 + EyeQ6L × 1 + 激光雷达处理单元
- **目标算力**：约 100 TOPS 组合算力
- **冗余设计**：三模冗余（TMR），具备 ASIL-D 安全完整性
- **目标场景**：Robotaxi、无人配送车等 L4 级商业化运营
- **合作方**：与 Volkswagen ID.Buzz 自动驾驶出租车项目合作

### 2.7 地平线征程 5

- **制程**：16nm（台积电）
- **AI 算力**：128 TOPS（INT8）
- **CPU**：8 核 ARM Cortex-A55
- **BPU**：地平线自研 BPU（Brain Processing Unit）第三代架构，专为视觉感知网络优化
- **功耗**：30 W（典型）
- **内存**：支持 LPDDR4X，带宽 51.2 GB/s
- **量产客户**：理想 L 系列（入门版）、长城、奇瑞、大众（合资智驾项目）等
- **特点**：提供较开放的 SDK（OpenExplorer），支持第三方算法部署，国内适配生态较完善

### 2.8 地平线征程 6 系列

- **制程**：8nm（三星）
- **型号矩阵**：J6E（128 TOPS）、J6M（256 TOPS）、J6H（560 TOPS）
- **发布时间**：2024 年开始陆续量产
- **架构升级**：BPU 第四代，支持 Transformer 类模型加速，显著提升端到端模型推理效率
- **内存带宽**：J6H 达 153.6 GB/s（LPDDR5）
- **目标场景**：覆盖 L2+ 至 L3 全场景，J6H 面向旗舰高阶智驾

### 2.9 高通 Snapdragon Ride Elite（SA8775P 等）

- **制程**：4nm（台积电）
- **AI 算力**：60+ TOPS（ADAS 专用引擎）
- **架构**：Kryo CPU（ARM V9）+ Adreno GPU + Hexagon DSP + Sensing Hub
- **集成度**：座舱域与驾驶域芯片融合（Cockpit + ADAS 合一 SoC）
- **量产客户**：吉利、上汽、宝马（座舱域）
- **特点**：高通 5G 通信基带集成，支持 V2X C-V2X 标准；AI 算力相对偏低，主要定位 L2+

### 2.10 华为昇腾（MDC 810 计算平台）

- **核心芯片**：昇腾 610 + 昇腾 310（异构组合）
- **AI 算力**：整板算力 400 TOPS
- **CPU**：鲲鹏 ARM 核心
- **功耗**：约 100 W
- **接口**：支持 8 路摄像头、3 路激光雷达、6 路毫米波雷达
- **量产客户**：北汽极狐 αS HI 版、阿维塔 11、问界 M9（HarmonyOS 智驾）
- **特点**：MindSpore 框架 + Atlas 平台完整闭环；华为提供"硬件+软件+算法"整体解决方案

### 2.11 主流 SoC 全面对比

| 芯片型号 | 厂商 | 制程 | AI 算力 | 功耗 | 内存带宽 | 量产客户（代表） | 市场定价区间 |
|---------|------|------|---------|------|----------|----------------|------------|
| Orin X  | NVIDIA | 12nm | 254 TOPS | 45 W | 204 GB/s | 理想、蔚来、小鹏 | ~$200（芯片裸价） |
| Thor    | NVIDIA | 4nm  | 2000 TOPS | ~100 W | 1 TB/s（预估） | 2025+ 旗舰车型 | 未公开 |
| FSD（HW3）| Tesla | 14nm | 144 TOPS | 72 W | 68 GB/s | Tesla 自用 | 内部成本 |
| AI5（HW4）| Tesla | 7nm 以下 | 300+ TOPS | ~80 W | 未公开 | Tesla 自用 | 内部成本 |
| EyeQ6H | Mobileye | 7nm | 34 TOPS | < 15 W | 未公开 | 宝马、通用 | < $100 |
| 征程 5  | 地平线 | 16nm | 128 TOPS | 30 W | 51.2 GB/s | 理想（低配）、长城 | ~￥300 |
| 征程 6H | 地平线 | 8nm  | 560 TOPS | 50 W | 153.6 GB/s | 2024+ 量产车 | 未公开 |
| Ride Elite | 高通 | 4nm | 60+ TOPS | 35 W | 未公开 | 吉利、上汽 | 中等 |
| MDC 810 | 华为 | N/A  | 400 TOPS | 100 W | 未公开 | 极狐、阿维塔、问界 | 较高 |


## 3. 异构计算架构详解

### 3.1 SoC 内部架构层次

以 NVIDIA Orin 为例，一颗 SoC 内部集成的功能单元包括：

```
┌─────────────────────────────────────────────────────────┐
│                   NVIDIA AGX Orin SoC                   │
│  ┌────────────┐  ┌────────────┐  ┌────────────────────┐ │
│  │ CPU Cluster│  │ GPU        │  │ DLA × 2            │ │
│  │ (12× A78AE)│  │ (2048 CUDA)│  │ (NVDLA v2.0)       │ │
│  └────────────┘  └────────────┘  └────────────────────┘ │
│  ┌────────────┐  ┌────────────┐  ┌────────────────────┐ │
│  │ ISP        │  │ PVA        │  │ Video Codec        │ │
│  │ (16ch 摄像)│  │ (可编程视觉)│  │ (H.265/VP9 编解码) │ │
│  └────────────┘  └────────────┘  └────────────────────┘ │
│  ┌────────────┐  ┌────────────────────────────────────┐ │
│  │ MCU        │  │ 安全岛（Lockstep Cortex-R52）       │ │
│  │ (实时控制) │  │ (ISO 26262 ASIL-D 隔离域)          │ │
│  └────────────┘  └────────────────────────────────────┘ │
│        片上互联：NVSwitch / AMBA CHI 网格总线              │
└─────────────────────────────────────────────────────────┘
```

### 3.2 任务分配策略

异构计算的核心优势在于让"合适的任务跑在合适的硬件上"，从而同时优化延迟与能效：

| 任务类型 | 推荐处理单元 | 典型时延要求 | 原因 |
|---------|------------|------------|------|
| 摄像头感知（目标检测/分割）| NPU / DLA | < 30 ms | 固定 CNN 结构，NPU 能效最优 |
| LiDAR 点云预处理（解码、过滤）| FPGA / DSP | < 5 ms | 数据量大，需确定性低延迟 |
| BEV 特征融合 | GPU | < 20 ms | Transformer 算子多样，GPU 灵活性强 |
| 路径规划（A* / Lattice Planner）| CPU | < 50 ms | 分支逻辑复杂，CPU 单线程性能更优 |
| 传感器数据同步与时间戳对齐 | MCU / 实时 CPU | < 1 ms | 硬实时需求 |
| 摄像头降噪 / HDR 处理 | ISP | < 3 ms | 专用硬件管线效率最高 |
| OTA 升级包校验 | HSM | 离线批处理 | 安全隔离环境，防篡改 |

### 3.3 内存层次架构

高吞吐量计算需要匹配的内存带宽，车载 SoC 通常采用多级存储层次：

- **片上 SRAM（L1/L2 Cache）**：容量 4～32 MB，带宽 > 1 TB/s，延迟 < 5 ns，CPU/GPU 核心私有缓存
- **片上 SRAM（NPU 专用）**：NPU 激活缓存，直接影响网络推理的批处理效率
- **LPDDR5 / LPDDR5X**：主内存，带宽 68～256 GB/s，延迟约 40～80 ns，CPU+GPU+NPU 共享
- **HBM2E（高带宽内存）**：部分高端平台（如 Tesla D1）采用，单通道带宽 > 460 GB/s，但成本更高
- **NAND Flash / UFS 3.1**：持久存储，用于操作系统镜像、模型文件、行车记录

### 3.4 带宽需求分析

一个典型 L3 自动驾驶感知系统的原始数据带宽估算：

| 传感器 | 数量 | 分辨率/帧率 | 单路带宽 | 合计带宽 |
|--------|------|-----------|---------|---------|
| 前向高分辨率摄像头 | 1 | 8MP @ 30fps | ~720 Mbps | ~720 Mbps |
| 环视摄像头 | 7 | 2MP @ 30fps | ~180 Mbps | ~1.26 Gbps |
| 固态激光雷达 | 1 | 100 线 @ 10Hz | ~200 Mbps | ~200 Mbps |
| 毫米波雷达 | 5 | 原始 ADC 数据 | ~20 Mbps | ~100 Mbps |
| **合计（传感器原始）** | - | - | - | **~2.3 Gbps** |

在 ISP 解码、点云过滤后进入 SoC 主内存的有效带宽约为 5～15 GB/s（考虑中间特征图的内存读写），这也是为何车载 SoC 必须配备超过 100 GB/s 的内存带宽。


## 4. 车规级要求

### 4.1 AEC-Q100 可靠性认证

AEC-Q100（汽车电子委员会 Q100 标准）是集成电路进入汽车供应链的基础门槛：

| 测试项目 | 要求 | 目的 |
|---------|------|------|
| 工作温度范围 | Grade 1：-40°C ～ +125°C | 覆盖高温暴晒与极寒启动 |
| 高温运行寿命（HTOL）| 1000 小时 @ 最高结温 | 验证长期热应力下芯片可靠性 |
| 湿热偏压测试（H3TRB）| 85°C / 85% RH，1000 小时 | 防止潮湿导致金属腐蚀与漏电 |
| 振动与冲击 | 符合 AEC-Q100-002/012 | 模拟路面颠簸对焊点的疲劳 |
| 静电放电（ESD）| HBM ≥ 2 kV | 防止装配过程中的静电损伤 |

### 4.2 ISO 26262 功能安全（ASIL 等级）

ISO 26262 是汽车功能安全国际标准，定义了汽车安全完整性等级（ASIL）从 A 到 D，D 级要求最严苛。

- **ASIL-B**：适用于辅助驾驶（L2）中的感知计算部分，允许单点故障检测概率 ≥ 99%
- **ASIL-D**：适用于制动、转向等执行机构的实时控制 MCU，要求硬件故障度量指标（SPFM）≥ 99%，LFM ≥ 90%

CCU 满足 ISO 26262 的常见硬件手段：
- **ECC 内存（Error Correcting Code）**：检测并纠正单比特错误，防止宇宙射线引起的软错误（SEU）
- **锁步（Lockstep）双核**：两颗相同核心同步执行，输出结果实时比较，任何差异触发安全告警
- **看门狗定时器（Watchdog）**：若软件死锁未及时喂狗，硬件强制复位系统
- **BIST（内建自测试）**：上电时对 CPU 缓存、NPU SRAM 执行自检，保证硬件初始状态正确

### 4.3 SOTIF（ISO 21448）对算法平台的要求

SOTIF（Safety Of The Intended Functionality，预期功能安全）关注系统在"没有故障"情况下，因功能局限或感知不足导致的危险。

对 CCU 硬件平台的影响：
- 需要足够算力以支持冗余感知模型（主模型 + 安全监督模型同时运行，互相校验输出）
- 需要提供高精度时间戳（< 1μs 精度），支持传感器数据融合的时间对齐
- 需要支持数据记录（黑匣子功能），用于事故后的 SOTIF 验证分析

### 4.4 硬件安全模块（HSM）与可信执行环境（TEE）

网联自动驾驶面临网络攻击风险，CCU 必须内置安全机制：

- **HSM（Hardware Security Module）**：芯片内独立安全核心（如 ARM TrustZone-M），管理密钥存储、安全启动（Secure Boot）、数字签名验证，与主计算区域物理隔离
- **TEE（Trusted Execution Environment）**：基于 ARM TrustZone-A 的隔离执行环境（如 OP-TEE），保护 OTA 升级包校验、车辆身份认证、敏感用户数据处理
- **安全启动链**：BootROM → BL1（HSM 签名验证）→ BL2（U-Boot）→ OS 内核，每一层验证下一层的数字签名，防止固件篡改
- **运行时完整性检测**：通过内核完整性度量（IMA）持续监控关键软件模块的哈希值，发现篡改立即告警


## 5. 算力趋势与展望

### 5.1 L2+ → L4 算力需求增长规律

自动驾驶等级提升对算力的需求近似遵循"算力摩尔定律"——每提升一个主要自动驾驶等级，所需算力增长约 5～10 倍：

| 自动驾驶等级 | 代表功能 | 典型算力需求 | 代表平台 |
|-----------|---------|-----------|---------|
| L1        | AEB 紧急制动、LKA 车道保持 | < 1 TOPS | Mobileye EyeQ2 |
| L2        | 高速领航辅助（NOA）| 5～30 TOPS | EyeQ4、Orin 小算力配置 |
| L2+       | 城市 NOA、记忆泊车 | 30～100 TOPS | 征程 5、Orin 单芯 |
| L3        | 特定场景有条件自动驾驶 | 100～500 TOPS | 双 Orin、MDC 810 |
| L4        | 特定区域完全自动驾驶 | 500～2000 TOPS | Thor、多芯级联 |
| L5        | 全场景无人驾驶 | > 2000 TOPS | 未来架构 |

从 L2 到 L4，算力需求约增长 100 倍，而这一跨越通常在 6～10 年内完成，对应芯片算力年均增长约 60%，远超传统消费芯片的摩尔定律速率（~40%/年）。

### 5.2 端到端大模型对车端算力的新需求

2023 年以来，Tesla FSD V12、华为 GOD 网络（通用障碍物检测）、UniAD 等端到端自动驾驶架构开始从学术走向量产，对车端 CCU 提出全新挑战：

- **模型参数量**：端到端模型参数量通常为 100M～10B，而传统模块化感知模型约 10M～100M，推理计算量增加 10～100 倍
- **输入模态**：直接以视频帧（而非单帧图像）作为输入，时序上下文窗口 4～16 帧，进一步放大计算需求
- **Transformer 算子**：多头自注意力机制的计算复杂度为 O(n²)，对 NPU 的 Transformer 加速能力要求更高
- **对策**：模型量化（INT8 → INT4）、剪枝、知识蒸馏、以及芯片侧专用 Transformer 加速单元（如征程 6 的 BPU v4）

### 5.3 车端推理 vs 云端训练的分工

```
┌──────────────────────────────────────────────────────────┐
│                    云端（数据中心）                         │
│  ┌─────────────────────────────────────────────────────┐ │
│  │ 海量行车数据（PB 级）→ 数据清洗 → 自动标注             │ │
│  │ GPU 集群训练（A100/H100/D1）→ 模型优化 → OTA 推送     │ │
│  └─────────────────────────────────────────────────────┘ │
└────────────────────────┬─────────────────────────────────┘
                         │ OTA（Over-The-Air 更新）
┌────────────────────────▼─────────────────────────────────┐
│                    车端（CCU）                              │
│  ┌─────────────────────────────────────────────────────┐ │
│  │ 实时推理（< 100ms 端到端延迟）                         │ │
│  │ 数据采集（Corner Case 上传）                           │ │
│  │ 本地增量学习（未来趋势）                                │ │
│  └─────────────────────────────────────────────────────┘ │
└──────────────────────────────────────────────────────────┘
```

当前阶段，车端 CCU 专注于推理，训练完全在云端完成。未来随着片上学习（On-Device Learning）技术成熟，车端可能支持小规模个性化增量训练，进一步降低对云端依赖、保护用户隐私。

### 5.4 国产芯片追赶进度

| 厂商 | 旗舰产品 | 当前量产算力 | 主要差距 | 追赶路径 |
|------|---------|-----------|---------|---------|
| 地平线 | 征程 6H | 560 TOPS | 软件生态成熟度 | 深化 BPU SDK、扩展国际客户 |
| 华为 | 昇腾 MDC 810 | 400 TOPS | 供应链受限（先进制程） | 国内自主制程突破 |
| 黑芝麻智能 | 华山 A2000 | 256 TOPS | 量产客户规模偏小 | 与主机厂深度绑定 |
| 芯驰科技 | X9SP | 8 TOPS | 定位 L2，算力较低 | 向 L2+ 升级 |
| 寒武纪行歌 | 思元 590（车规版）| 256 TOPS（非车规）| 车规认证进行中 | AEC-Q100 认证突破 |

国产车规芯片在 2024～2025 年已在中低端智驾市场形成一定竞争力，但在最先进制程（4nm 以下）、软件生态完整度和全球量产经验方面仍与 NVIDIA 存在明显差距。随着国内主机厂对供应链安全的重视，"国产替代"战略将持续加速国产 CCU 芯片的商业化进程。


## 参考资料

1. NVIDIA. "DRIVE AGX Orin Technical Brief." NVIDIA Developer Documentation, 2023. https://developer.nvidia.com/drive/agx
2. Tesla. "Tesla AI Day 2021: FSD Computer Architecture." Tesla Technical Presentations, 2021. https://youtu.be/j0z4FweCy4M
3. Mobileye. "EyeQ6 Product Brief." Mobileye Technology White Papers, 2023. https://www.mobileye.com/technology/eyeq-chip/
4. 地平线. 《征程 6 系列芯片技术白皮书》. 地平线官方技术文档, 2024. https://www.horizon.ai
5. ISO. "ISO 26262:2018 — Road vehicles — Functional safety." International Organization for Standardization, 2018.
6. 工业和信息化部. 《智能网联汽车车载计算平台参考架构》. 中国智能网联汽车产业创新联盟（CAICV）标准白皮书, 2023.
